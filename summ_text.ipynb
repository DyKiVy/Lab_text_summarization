{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "evOtSwsb3Lsu"
      },
      "source": [
        "!pip install transformers sentencepiece datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qnO-6svtJO95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"IlyaGusev/gazeta\")"
      ],
      "metadata": {
        "id": "MYd2hGgbqFCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWj89UDZ3Ep0"
      },
      "source": [
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "model_name = \"IlyaGusev/rut5_base_sum_gazeta\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "def gen_batch(inputs, batch_size):\n",
        "    batch_start = 0\n",
        "    while batch_start < len(inputs):\n",
        "        yield inputs[batch_start: batch_start + batch_size]\n",
        "        batch_start += batch_size\n",
        "\n",
        "\n",
        "def predict(\n",
        "    model_name,\n",
        "    input_records,\n",
        "    output_file,\n",
        "    max_source_tokens_count=400,\n",
        "    max_target_tokens_count=200,\n",
        "    batch_size=96\n",
        "):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_name).half().to(device)\n",
        "\n",
        "    predictions = []\n",
        "    for batch in tqdm(gen_batch(input_records, batch_size)):\n",
        "        texts = [r[\"text\"] for r in batch]\n",
        "        input_ids = tokenizer(\n",
        "            texts,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_source_tokens_count,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )[\"input_ids\"].to(device)\n",
        "\n",
        "        output_ids = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_length=max_target_tokens_count,\n",
        "            no_repeat_ngram_size=3,\n",
        "            early_stopping=True,\n",
        "            num_beams=2\n",
        "        )\n",
        "        summaries = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "        #for s in summaries:\n",
        "        #    print(s)\n",
        "        predictions.extend(summaries)\n",
        "    with open(output_file, \"w\") as w:\n",
        "        for p in predictions:\n",
        "            w.write(p.strip().replace(\"\\n\", \" \") + \"\\n\")\n",
        "\n",
        "gazeta_test = load_dataset('IlyaGusev/gazeta', revision=\"v1.0\")[\"test\"]\n",
        "predict(\"IlyaGusev/rut5_base_sum_gazeta\", list(gazeta_test), \"t5_predictions.txt\")"
      ],
      "metadata": {
        "id": "Xb9ZagiKgulo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_text = input()\n",
        "\n",
        "input_ids = tokenizer(\n",
        "    [article_text],\n",
        "    add_special_tokens=True,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=400,\n",
        "    return_tensors=\"pt\"\n",
        ")[\"input_ids\"]\n",
        "\n",
        "output_ids = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    no_repeat_ngram_size=3,\n",
        "    num_beams=5,\n",
        "    early_stopping=True\n",
        ")[0]\n",
        "\n",
        "summary = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua3kUgz5e_8H",
        "outputId": "6c5df1a0-52bc-4fbc-a0b9-da348fa8596d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Когда человек рождается, он начинает проходить процесс развития, познавать открывшийся ему мир, ему раскрываются смысл и ценности жизни, а от его состояния зависит трудоспособность человека. Для того, чтобы здоровье было на более высоком уровне, необходимо придерживаться здоровому образу жизни, который включает в себя основные элементы здоровья.\n"
          ]
        }
      ]
    }
  ]
}
